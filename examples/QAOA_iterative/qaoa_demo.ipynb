{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('../../src/')\n",
    "sys.path.append('../../src')\n",
    "import stochastic_benchmark as SB\n",
    "import numpy as np\n",
    "import os\n",
    "import bootstrap\n",
    "import interpolate\n",
    "import stats\n",
    "from utils_ws import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a `stochastic_benchmark` object\n",
    "The primary class we will use is the `stochastic_benchmark` class in the `stochastic_benchmark` module. \n",
    "Run the cell below to instantiate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = os.getcwd()\n",
    "parameter_names = ['iterations', 'shots', 'rounds'] # think about whether iterations should be a parameter or not.\n",
    "instance_cols = ['instance'] #indicates how instances should be grouped, default is ['instance']\n",
    "\n",
    "## Response information \n",
    "response_key = 'approx_ratio' # Column with the response\n",
    "response_dir = 1 # whether we want to maximize (1) or minimize (-1), default is 1\n",
    "\n",
    "## Optimizations informations\n",
    "recover = True #Whether we want to read dataframes when available, default is True\n",
    "reduce_mem = True #Whether we want to segment bootstrapping and interpolation to reduce memory usage, default is True\n",
    "smooth = True  #Whether virtual best should be monontonized, default is True\n",
    "\n",
    "sb = SB.stochastic_benchmark(parameter_names=parameter_names, here=here, instance_cols=instance_cols, response_key=response_key, response_dir=response_dir, smooth=smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bootstrap data\n",
    "The cell below can be used to generate bootstrapped data from raw data. In this demo however, bootstrapped data for 10 problem instances is already stored in the `checkpoints` folder. Running the cell below will load that data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Bootstrap data. \n",
    "# The data is already boostrapped, but needs to be loaded into memory\n",
    "shared_args = {'response_col':\"approx_ratio\",\n",
    "               'resource_col':\"resource\",\n",
    "               'response_dir':1,\n",
    "               'confidence_level':68}\n",
    "boots_range = [1,2,5, 10, 20, 50, 100]\n",
    "bsParams = bootstrap.BootstrapParameters(shared_args=shared_args, update_rule= lambda df: None)\n",
    "bs_iter_class = bootstrap.BSParams_range_iter()\n",
    "bsParams_iter = bs_iter_class(bsParams, boots_range)\n",
    "sb.run_Bootstrap(bsParams_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "The data from each instance might be available at different values of resource. Using interpolation, obtain estimates for the performance and parameters at the same grid of resource values for each instance. \n",
    "\n",
    "To that end, it is necessary to define a notion of the amount of resources used for each run. In the iterative QAOA, a reasonable measure of the amount of resources used is the number of times the quantum hardware was accessed. That is, we define the amount of resources to be equal to the product of the number of shots, the number of restarts (called `boots` in the bootstrap `pkl` data), and the number of minimizer iterations, COBYLA for this demo. The resource calculation should be specified as a function (`resource_fun` in the cell below), which will then be passed to the interpolation method. Other ways of defining the resource are also valid (for example, in terms of the amount of QPU time), but we use the function below for this demo.\n",
    "\n",
    "The results of the interpolation for all instances are stored in a single file- `checkpoints/interpolated_results.pkl`, and are loaded into memory in the form of a dataframe that can be accessed using `sb.interp_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate\n",
    "def resource_fcn(df):\n",
    "    return df['boots'] * df['iterations'] * df['shots']\n",
    "iParams = interpolate.InterpolationParameters(resource_fcn,\n",
    "                                              parameters=parameter_names)\n",
    "sb.run_Interpolate(iParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into test and train instances\n",
    "If `train_test_split=0.8`, $80\\%$ of the instances will be labeled as train instances, while the remaining will form the test data.\n",
    "The `run_Stats` method will implement this splitting, adding a column called `train` to `sb.interp_results`. The updated dataframe is also stored in `checkpoints/interpolated_results.pkl`.\n",
    "\n",
    "In addition, `run_Stats` computes various statistics for the test and train sets separately and stores the data in the form of dataframes, in `checkpoints/testng_stats.pkl` and `checkpoints/training_stats.pkl` respectively. They are also stored in memory and can be accessed as `sb.testing_stats` and `sb.training_stats`. The statistic of interest can be specified by instantiating `stats.StatsParameters` appropriately. For this demo, we prefer to compute the median, $75\\%$ quantile and the $25\\%$ quantile for the response (the approximation ratio). One may instead choose to compute the mean and the $68\\%$ confidence interval (assuming a gaussian distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Stats computations\n",
    "train_test_split = 0.5\n",
    "metrics = [\"approx_ratio\"]\n",
    "stParams = stats.StatsParameters(metrics=metrics, stats_measures=[stats.Median()])\n",
    "sb.run_Stats(stParams, train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the virtual best baseline\n",
    "For the testing set, the cell below computes the best performance and parameters observed for the testing instance. The output is stored in `checkpoints/VirtualBest_test.pkl` and also in working memory (`sb.baseline.rec_params`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.run_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection Experiments\n",
    "Descriptions to be added soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.run_ProjectionExperiment('TrainingStats', None, None)\n",
    "sb.run_ProjectionExperiment('TrainingResults', None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the performane and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.initPlotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = sb.plots.plot_performance()\n",
    "fig.savefig('performance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = sb.plots.plot_parameters_separate()\n",
    "for param, fig in figs.items():\n",
    "    fig.savefig(param+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = sb.plots.plot_parameters_together()\n",
    "fig.savefig('all_params.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('SB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c746e22876cc9517b5ed57bd6907ecbc9cc9ab46f774569dcfc1ac4f0995eba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
